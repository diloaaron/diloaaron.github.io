---
title: "Thesis Data Work"
author: Aaron DiLorenzo
date: "January 11, 2024"
format: 
  html:
    theme: cosmo
    toc: true
    toc-depth: 4
    toc-expand: 2
    code-fold: show
    code-summary: "Show code"
    code-link: true
    code-overflow: scroll
    code-line-numbers: true
    code-copy: true
    include-in-header:
      text: |
        <style>
        /* Replace "Published" with "Last updated" */
        .quarto-title-block .date::before {
          content: "Last updated: ";
          display: inline;
        }
        .quarto-title-block .date em {
          display: none;
        }
        </style>
    
execute: 
  echo: true      
  eval: false     
  warning: false
  message: false
  fig.show: "hide"
  
number-sections: true
self-contained: true  
---

### Python Code for Merged and Transformed PQI Data

```{python}
"""
OECD Patent Quality Indicators - Data Processing Script
Merging, normalization, and aggregation of patent quality data
"""


import polars as pl
import os


# Configuration
OUTPUT_DIR = "/Users/aarondilorenzo/Desktop/DATATHES/FINAL WORKING DATA"
os.makedirs(OUTPUT_DIR, exist_ok=True)


# Input files
INDICATORS_FILE = "/Users/aarondilorenzo/Desktop/DATATHES/202502_OECD_PATENT_QUALITY_EPO_INDIC.txt"
COHORTS_FILE = "/Users/aarondilorenzo/Desktop/DATATHES/202502_OECD_PATENT_QUALITY_EPO_INDIC_COHORT.txt"
HAN_PATENTS_FILE = "/Users/aarondilorenzo/Desktop/DATATHES/202502_HAN_PATENTS.txt"
HARM_NAMES_FILE = "/Users/aarondilorenzo/Desktop/DATATHES/202502_HARM_NAMES.txt"


# Output files
FINAL_PATENT_FILE = "OECD_patent_quality_final.parquet"
FINAL_COUNTRY_FILE = "OECD_country_year_final.csv"


# Indicator categories
WINSOR_VARS = ["family_size", "grant_lag", "bwd_cits", "npl_cits", "claims", "fwd_cits5", "fwd_cits7"]
COMPOSITE_VARS = ["generality", "originality", "radicalness", "quality_index_4", "quality_index_6"]
BINARY_VARS = ["breakthrough"]


def load_data():
    """Load and prepare all source datasets"""
    
    # Load cohort statistics for normalization
    cohorts = pl.read_csv(
        COHORTS_FILE,
        separator="|",
        null_values=["", "NA"],
        dtypes={col: pl.Utf8 for col in [
            "filing", "tech_field", "variable", "patents", "mean", "std_dev", 
            "kurtosis", "skewness", "p1", "p10", "p25", "p50", "p75", "p90", "p99", "max"
        ]},
        infer_schema_length=0
    )
    
    # Clean column names and convert numeric types
    cohorts = cohorts.rename({col: col.strip() for col in cohorts.columns})
    numeric_cols = ["p1", "p10", "p25", "p50", "p75", "p90", "p99", "max"]
    for col in numeric_cols:
        if col in cohorts.columns:
            cohorts = cohorts.with_columns(pl.col(col).cast(pl.Float64))
    
    cohorts = cohorts.select(["filing", "tech_field", "variable", "p1", "p99", "max"])
    
    # Load main indicator data
    indicators = pl.read_csv(
        INDICATORS_FILE, 
        separator="|", 
        null_values=["", "NA"],
        infer_schema_length=10000
    )
    indicators = indicators.rename({col: col.strip() for col in indicators.columns})
    
    # Load and prepare HAN/HARM mapping data
    han = pl.read_csv(HAN_PATENTS_FILE, separator="|")
    han = han.rename({col: col.strip() for col in han.columns})
    han = han.rename({"Appln_id": "appln_id"})
    
    harm = pl.read_csv(HARM_NAMES_FILE, separator="|")
    harm = harm.rename({col: col.strip() for col in harm.columns})
    harm = harm.select(["HARM_ID", "Clean_name", "Person_ctry_code"])
    
    han = han.join(harm, on="HARM_ID", how="left").select(["appln_id", "HARM_ID", "Clean_name", "Person_ctry_code"])
    
    return cohorts, indicators, han


def apply_cohort_normalization(merged, cohorts, indicator_name, winsorize=True):
    """Apply cohort-specific normalization and winsorization"""
    
    col_stats = cohorts.filter(pl.col("variable") == indicator_name)
    
    if col_stats.is_empty():
        return merged
    
    merged = merged.join(
        col_stats.select(["filing", "tech_field", "p1", "p99", "max"]),
        on=["filing", "tech_field"],
        how="left"
    )
    
    # Special handling for grant_lag transformation
    if indicator_name == "grant_lag":
        merged = merged.with_columns(
            (1 - (pl.col("grant_lag") / pl.col("max"))).alias("grant_lag_transformed")
        )
        
        if winsorize:
            merged = merged.with_columns(
                pl.when(pl.col("grant_lag_transformed") < (1 - pl.col("p99")/pl.col("max"))).then(1 - pl.col("p99")/pl.col("max"))
                .when(pl.col("grant_lag_transformed") > (1 - pl.col("p1")/pl.col("max"))).then(1 - pl.col("p1")/pl.col("max"))
                .otherwise(pl.col("grant_lag_transformed"))
                .alias("grant_lag_transformed_winsorized")
            )
            merged = merged.with_columns(
                pl.col("grant_lag_transformed_winsorized").alias("grant_lag_norm")
            ).drop(["grant_lag_transformed_winsorized", "p1", "p99", "max", "grant_lag_transformed"])
        else:
            merged = merged.with_columns(
                pl.col("grant_lag_transformed").alias("grant_lag_norm")
            ).drop(["p1", "p99", "max", "grant_lag_transformed"])
    
    else:
        # Standard normalization for other indicators
        if winsorize and indicator_name in WINSOR_VARS:
            merged = merged.with_columns(
                pl.when(pl.col(indicator_name) < pl.col("p1")).then(pl.col("p1"))
                .when(pl.col(indicator_name) > pl.col("p99")).then(pl.col("p99"))
                .otherwise(pl.col(indicator_name))
                .alias(f"{indicator_name}_winsorized")
            )
            merged = merged.with_columns(
                (pl.col(f"{indicator_name}_winsorized") / pl.col("max")).alias(f"{indicator_name}_norm")
            ).drop([f"{indicator_name}_winsorized", "p1", "p99", "max"])
        else:
            merged = merged.with_columns(
                (pl.col(indicator_name) / pl.col("max")).alias(f"{indicator_name}_norm")
            ).drop(["p1", "p99", "max"])
    
    return merged


def main():
    """Main data processing pipeline"""
    
    # Load data
    cohorts, indicators, han = load_data()
    
    # Ensure consistent data types
    indicators = indicators.with_columns([
        pl.col("filing").cast(pl.Utf8),
        pl.col("tech_field").cast(pl.Utf8)
    ])
    
    cohorts = cohorts.with_columns([
        pl.col("filing").cast(pl.Utf8),
        pl.col("tech_field").cast(pl.Utf8)
    ])
    
    # Merge with HAN/HARM data
    merged = indicators.join(han, on="appln_id", how="left")
    
    # Apply normalization by indicator type
    standard_indicators = ["patent_scope", "family_size", "grant_lag", "bwd_cits", "npl_cits", "claims", "fwd_cits5", "fwd_cits7"]
    
    for indicator in standard_indicators:
        if indicator in merged.columns:
            merged = apply_cohort_normalization(merged, cohorts, indicator, winsorize=True)
    
    # Handle composite indicators (use as-is)
    # Handle breakthrough (binary indicator)
    if "breakthrough" in merged.columns:
        merged = merged.with_columns([
            pl.col("breakthrough").fill_null(0).cast(pl.Int8).alias("breakthrough")
        ])
    
    # Handle renewal (raw counts)
    if "renewal" in merged.columns:
        merged = merged.with_columns([
            pl.col("renewal").cast(pl.Float64).alias("renewal")
        ])
    
    # Aggregate to country-year level
    norm_columns = [col for col in merged.columns if col.endswith('_norm')]
    
    agg_exprs = []
    
    # Normalized indicators: take mean
    for col in norm_columns:
        agg_exprs.append(pl.mean(col).alias(f"avg_{col}"))
    
    # Composite indicators: take mean of raw values
    for col in COMPOSITE_VARS:
        if col in merged.columns:
            agg_exprs.append(pl.mean(col).alias(f"avg_{col}"))
    
    # Breakthrough: calculate percentage
    if "breakthrough" in merged.columns:
        agg_exprs.append(
            (pl.sum("breakthrough") / pl.count("breakthrough")).alias("pct_breakthrough")
        )
    
    # Renewal: average renewal count
    if "renewal" in merged.columns:
        agg_exprs.append(pl.mean("renewal").alias("avg_renewal"))
    
    # Perform aggregation
    country_agg = (
        merged
        .filter(pl.col("Person_ctry_code").is_not_null())
        .group_by(["Person_ctry_code", "filing"])
        .agg(agg_exprs)
        .rename({"Person_ctry_code": "country_code", "filing": "year"})
        .sort(["country_code", "year"])
    )
    
    # Save final datasets
    patent_path = os.path.join(OUTPUT_DIR, FINAL_PATENT_FILE)
    merged.write_parquet(patent_path)
    
    country_path = os.path.join(OUTPUT_DIR, FINAL_COUNTRY_FILE)
    country_agg.write_csv(country_path)


if __name__ == "__main__":
    main()



```
### Merging all the data
```{python}
'''
Master Panel Script - combines financial development data, ipr data, quality data, and controls
'''
import pandas as pd
import os

# Set directory
data_dir = "/Users/aarondilorenzo/Desktop/DATATHES/FINAL WORKING DATA"

files = {
    "quality": "quality_final.csv",
    "vc": "VC_final.csv",
    "park": "Park_final.csv",
    "controls": "Controls_final.csv",
    "finance": "FD_Final.csv",
    "counts": "Counts_res_final.csv"
}

dfs = {}
for key, fname in files.items():
    path = os.path.join(data_dir, fname)
    print(f"Reading {fname} ...")
    try:
        df = pd.read_csv(path)

        # Standardize column names
        for col in df.columns:
            if col.lower() in ["iso3", "iso3c", "country_code"]:
                df = df.rename(columns={col: "iso3c"})
            if col.lower() in ["country", "country name"]:
                df = df.rename(columns={col: "country_name"})
        cols = [c for c in df.columns if c != "country_name"]
        df = df[["iso3c", "year", "country_name"] + [c for c in cols if c not in ["iso3c", "year"]]]

        
        if "year" in df.columns:
            df["year"] = df["year"].astype(int)

        dfs[key] = df

    except Exception as e:
        print(f"eror reading {fname}: {e}")

# Merge
master = None
for name, df in dfs.items():
    if master is None:
        master = df
    else:
        # Drop duplicate country_name column if it already exists in master
        if "country_name" in master.columns and "country_name" in df.columns:
            df = df.drop(columns=["country_name"])
        master = pd.merge(master, df, on=["iso3c", "year"], how="outer")

# sort and organize
master = master.sort_values(["iso3c", "year"]).reset_index(drop=True)

# save
out_path = os.path.join(data_dir, "Master_Panel.csv")
master.to_csv(out_path, index=False)
```


### R code for running regressions

```{r}
rm(list = ls())
install.packages("reticulate")
library(reticulate)
library(tidyverse)
library(plm)
library(stargazer)
library(data.table)
library(lmtest)
library(sandwich)

master <- fread("~/Desktop/DATATHES/FINAL WORKING DATA/Master_Panel.csv")

master_clean <- master %>%
  mutate(researchers_per_million = coalesce(researchers_per_million_y, researchers_per_million_x)) %>%
  mutate(across(c(
    year, avg_quality_index_4, avg_quality_index_6, VC_investment,
    bank_credit_gdp, market_cap_gdp, ipp_index_IP_transformed,
    patent_applications_residents, researchers_per_million,
    gdp_pc_const2015usd, trade_percent_gdp,
    rd_expenditure_percent_gdp, tertiary_enrollment_percent
  ), as.numeric)) %>%
  mutate(VC_investment_pct = VC_investment * 100) %>%
  mutate(quality_index_100 = avg_quality_index_4 * 100) %>%
  mutate(patents_per_researcher = patent_applications_residents / researchers_per_million) %>%
  
  mutate(
    bank_x_ipr = bank_credit_gdp * ipp_index_IP_transformed,
    market_x_ipr = market_cap_gdp * ipp_index_IP_transformed,
    vc_x_ipr = VC_investment_pct * ipp_index_IP_transformed
  )

master_clean <- pdata.frame(master_clean, index = c("iso3c", "year"))

master_levels <- master_clean %>%
  filter(!is.na(quality_index_100) | !is.na(patents_per_researcher)) %>%
  filter(!is.na(bank_credit_gdp) | !is.na(market_cap_gdp) | !is.na(VC_investment_pct)) %>%
  filter(!is.na(ipp_index_IP_transformed))

year_range <- range(as.numeric(as.character(master_levels$year)), na.rm = TRUE)

master_bank_market <- master_levels %>% 
  filter(!is.na(bank_credit_gdp) | !is.na(market_cap_gdp))

master_vc <- master_levels %>% 
  filter(!is.na(VC_investment_pct))

# PATENT QUALITY REGRESSIONS

# Bank-based FD with IPR interaction
qual_bank <- plm(quality_index_100 ~ bank_credit_gdp + ipp_index_IP_transformed + bank_x_ipr +
                   gdp_pc_const2015usd + trade_percent_gdp +
                   rd_expenditure_percent_gdp + tertiary_enrollment_percent,
                 data = master_bank_market, model = "within", effect = "twoways")

# Market-based FD with IPR interaction  
qual_market <- plm(quality_index_100 ~ market_cap_gdp + ipp_index_IP_transformed + market_x_ipr +
                     gdp_pc_const2015usd + trade_percent_gdp +
                     rd_expenditure_percent_gdp + tertiary_enrollment_percent,
                   data = master_bank_market, model = "within", effect = "twoways")

# VC-based FD with IPR interaction
qual_vc <- plm(quality_index_100 ~ VC_investment_pct + ipp_index_IP_transformed + vc_x_ipr +
                 gdp_pc_const2015usd + trade_percent_gdp +
                 rd_expenditure_percent_gdp + tertiary_enrollment_percent,
               data = master_vc, model = "within", effect = "twoways")

# patent count regressions

# Bank FD with IPR interaction
count_bank <- plm(patents_per_researcher ~ bank_credit_gdp + ipp_index_IP_transformed + bank_x_ipr +
                    gdp_pc_const2015usd + trade_percent_gdp +
                    rd_expenditure_percent_gdp + tertiary_enrollment_percent,
                  data = master_bank_market, model = "within", effect = "twoways")

# market FD with IPR interaction
count_market <- plm(patents_per_researcher ~ market_cap_gdp + ipp_index_IP_transformed + market_x_ipr +
                      gdp_pc_const2015usd + trade_percent_gdp +
                      rd_expenditure_percent_gdp + tertiary_enrollment_percent,
                    data = master_bank_market, model = "within", effect = "twoways")

# VC FD with IPR interaction
count_vc <- plm(patents_per_researcher ~ VC_investment_pct + ipp_index_IP_transformed + vc_x_ipr +
                  gdp_pc_const2015usd + trade_percent_gdp +
                  rd_expenditure_percent_gdp + tertiary_enrollment_percent,
                data = master_vc, model = "within", effect = "twoways")

# clustering se
qual_bank_se <- sqrt(diag(vcovHC(qual_bank, type = "HC1", cluster = "group")))
qual_market_se <- sqrt(diag(vcovHC(qual_market, type = "HC1", cluster = "group")))
qual_vc_se <- sqrt(diag(vcovHC(qual_vc, type = "HC1", cluster = "group")))

count_bank_se <- sqrt(diag(vcovHC(count_bank, type = "HC1", cluster = "group")))
count_market_se <- sqrt(diag(vcovHC(count_market, type = "HC1", cluster = "group")))
count_vc_se <- sqrt(diag(vcovHC(count_vc, type = "HC1", cluster = "group")))

# stargazer tables with clustered se

stargazer(qual_bank, qual_market, qual_vc,
          type = "text",
          title = "Financial Development, IP Protection and Patent Quality",
          dep.var.labels = "Patent Quality Index (0-100 scale)",
          column.labels = c("Bank-based", "Market-based", "VC-based"),
          covariate.labels = c("Bank Credit/GDP", "Market Cap/GDP", "VC Investment/GDP",
                               "IP Protection", 
                               "Bank FD × IP Protection", 
                               "Market FD × IP Protection",
                               "VC FD × IP Protection",
                               "GDP per Capita", "Trade/GDP", 
                               "R&D Expenditure", "Tertiary Enrollment"),
          omit.stat = c("ser", "f"),
          se = list(qual_bank_se, qual_market_se, qual_vc_se),
          notes = "All specifications include country and year fixed effects. Patent quality measured on 0-100 scale. Standard errors clustered by country in parentheses.",
          notes.append = FALSE,
          align = TRUE)


stargazer(count_bank, count_market, count_vc,
          type = "text",
          title = "Financial Development, IP Protection and Patent Counts per Researcher",
          dep.var.labels = "Patents per Researcher",
          column.labels = c("Bank-based", "Market-based", "VC-based"),
          covariate.labels = c("Bank Credit/GDP", "Market Cap/GDP", "VC Investment/GDP",
                               "IP Protection", 
                               "Bank FD × IP Protection", 
                               "Market FD × IP Protection",
                               "VC FD × IP Protection",
                               "GDP per Capita", "Trade/GDP", 
                               "R&D Expenditure", "Tertiary Enrollment"),
          omit.stat = c("ser", "f"),
          se = list(count_bank_se, count_market_se, count_vc_se),
          notes = "All specifications include country and year fixed effects. All financial development measures in % of GDP. Standard errors clustered by country in parentheses.",
          notes.append = FALSE,
          align = TRUE)
##
# SAMPLE SIZE REPORT
#cat("\n\n")
#cat("===============================================================================\n")
#cat("SAMPLE SIZES\n")
#cat("===============================================================================\n")
#cat("Bank/Market Models:\n")
#cat("  Quality:", nobs(qual_bank), "observations\n")
#cat("  Counts:", nobs(count_bank), "observations\n")
#cat("VC Models:\n")
#cat("  Quality:", nobs(qual_vc), "observations\n")
#cat("  Counts:", nobs(count_vc), "observations\n")
#cat("Countries (Bank/Market):", length(unique(master_bank_market$iso3c)), "\n")
#cat("Countries (VC):", length(unique(master_vc$iso3c)), "\n")
#cat("Years:", paste0(year_range, collapse = " - "), "\n")

stargazer(qual_bank, qual_market, qual_vc,
          type = "html",
          title = "Financial Development, IP Protection and Patent Quality",
          dep.var.labels = "Patent Quality Index (0-100 scale)",
          column.labels = c("Bank-based", "Market-based", "VC-based"),
          covariate.labels = c("Bank Credit/GDP", "Market Cap/GDP", "VC Investment/GDP",
                               "IP Protection", 
                               "Bank FD × IP Protection", 
                               "Market FD × IP Protection",
                               "VC FD × IP Protection",
                               "GDP per Capita", "Trade/GDP", 
                               "R&D Expenditure", "Tertiary Enrollment"),
          omit.stat = c("ser", "f"),
          se = list(qual_bank_se, qual_market_se, qual_vc_se),
          notes = "All specifications include country and year fixed effects. Patent quality measured on 0-100 scale. Standard errors clustered by country in parentheses.",
          notes.append = FALSE,
          align = TRUE,
          out = "~/Desktop/quality_table.html")

stargazer(count_bank, count_market, count_vc,
          type = "html",
          title = "Financial Development, IP Protection and Patent Counts per Researcher",
          dep.var.labels = "Patents per Researcher",
          column.labels = c("Bank-based", "Market-based", "VC-based"),
          covariate.labels = c("Bank Credit/GDP", "Market Cap/GDP", "VC Investment/GDP",
                               "IP Protection", 
                               "Bank FD × IP Protection", 
                               "Market FD × IP Protection",
                               "VC FD × IP Protection",
                               "GDP per Capita", "Trade/GDP", 
                               "R&D Expenditure", "Tertiary Enrollment"),
          omit.stat = c("ser", "f"),
          se = list(count_bank_se, count_market_se, count_vc_se),
          notes = "All specifications include country and year fixed effects. All financial development measures in % of GDP. Standard errors clustered by country in parentheses.",
          notes.append = FALSE,
          align = TRUE,
          out = "~/Desktop/count_table.html")

stargazer(qual_bank, qual_market, qual_vc,
          type = "text",
          title = "Financial Development, IP Protection and Patent Quality",
          dep.var.labels = "Patent Quality Index (0-100 scale)",
          column.labels = c("Bank-based", "Market-based", "VC-based"),
          covariate.labels = c("GDP per Capita", "Trade/GDP", "R&D Expenditure", "Tertiary Enrollment",  
                               "Bank Credit/GDP", "Market Cap/GDP", "VC Investment/GDP",  
                               "IP Protection", 
                               "Bank FD × IP Protection", "Market FD × IP Protection", "VC FD × IP Protection"),
          keep = c("bank_credit_gdp", "market_cap_gdp", "VC_investment_pct",  
                   "ipp_index_IP_transformed", "bank_x_ipr", "market_x_ipr", "vc_x_ipr",
                   "gdp_pc_const2015usd", "trade_percent_gdp", "rd_expenditure_percent_gdp", "tertiary_enrollment_percent"),
          omit.stat = c("ser", "f"),
          se = list(qual_bank_se, qual_market_se, qual_vc_se),
          notes = "All specifications include country and year fixed effects. Standard errors clustered by country.",
          notes.append = FALSE,
          align = TRUE)
```
