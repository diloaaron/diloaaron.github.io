---
title: "Thesis Data Work"
author: Aaron DiLorenzo
date: "Feb 15, 2026"
format: 
  html:
    theme: cosmo
    toc: true
    toc-depth: 4
    toc-expand: 2
    code-fold: show
    code-summary: "Show code"
    code-link: true
    code-overflow: scroll
    code-line-numbers: true
    code-copy: true
    include-in-header:
      text: |
        <style>
        /* Replace "Published" with "Last updated" */
        .quarto-title-block .date::before {
          content: "Last updated: ";
          display: inline;
        }
        .quarto-title-block .date em {
          display: none;
        }
        </style>
    
execute:
  enabled: true
  python: false

  echo: true      
  eval: true     
  warning: false
  message: true
  cache: true
  freeze: auto
  
number-sections: true
self-contained: true  
---
# python pqi script
```{python, eval=FALSE}
"""
OECD Patent Quality Indicators
normalization, winsorization, and aggregation procedures
"""

import polars as pl
import os

OUTPUT_DIR = "/Users/aarondilorenzo/Desktop/DATATHES/FINAL WORKING DATA"
os.makedirs(OUTPUT_DIR, exist_ok=True)
# for reproducing, change the file paths to correctly the downloaded data, 
# they're too large for me to make this self running
INDICATORS_FILE = "Data/202502_OECD_PATENT_QUALITY_EPO_INDIC.txt"
COHORTS_FILE = "Data/202502_OECD_PATENT_QUALITY_EPO_INDIC_COHORT.txt"
HAN_PATENTS_FILE = "Data/202502_HAN_PATENTS.txt"
HARM_NAMES_FILE = "Data/DATATHES/202502_HARM_NAMES.txt"

FINAL_PATENT_FILE = "OECD_patent_quality_final.parquet"
FINAL_COUNTRY_FILE = "OECD_country_year_final.csv"

WINSOR_VARS = ["family_size", "grant_lag", "bwd_cits", "npl_cits", "claims", "fwd_cits5", "fwd_cits7"]
COMPOSITE_VARS = ["generality", "originality", "radicalness", "quality_index_4", "quality_index_6"]

# load the data

def load_data():

    cohorts = pl.read_csv(COHORTS_FILE, separator="|", infer_schema_length=0)
    cohorts = cohorts.rename({c: c.strip() for c in cohorts.columns})

    indicators = pl.read_csv(INDICATORS_FILE, separator="|", infer_schema_length=10000)
    indicators = indicators.rename({c: c.strip() for c in indicators.columns})

    han = pl.read_csv(HAN_PATENTS_FILE, separator="|")
    han = han.rename({c: c.strip() for c in han.columns})
    han = han.rename({"Appln_id": "appln_id"})

    harm = pl.read_csv(HARM_NAMES_FILE, separator="|")
    harm = harm.rename({c: c.strip() for c in harm.columns})
    harm = harm.select(["HARM_ID", "Person_ctry_code"])

    han = han.join(harm, on="HARM_ID", how="left")

    return cohorts, indicators, han

# main function

def main():

    cohorts, indicators, han = load_data()

    merged = indicators.join(han, on="appln_id", how="left")

    # ensure breakthrough is binary
    if "breakthrough" in merged.columns:
        merged = merged.with_columns(
            pl.col("breakthrough").fill_null(0).cast(pl.Int8)
        )

    # aggregation to country/year

    agg_exprs = []

    # normalized indicators
    norm_cols = [c for c in merged.columns if c.endswith("_norm")]
    for c in norm_cols:
        agg_exprs.append(pl.mean(c).alias(f"avg_{c}"))

    # mean for composite indicator
    for c in COMPOSITE_VARS:
        if c in merged.columns:
            agg_exprs.append(pl.mean(c).alias(f"avg_{c}"))

    # breakthrough counts
    agg_exprs.extend([
        pl.sum("breakthrough").alias("breakthrough_count"),
        pl.count("appln_id").alias("patent_count"),
        (pl.sum("breakthrough") / pl.count("appln_id")).alias("pct_breakthrough")
    ])

    country_agg = (
        merged
        .filter(pl.col("Person_ctry_code").is_not_null())
        .group_by(["Person_ctry_code", "filing"])
        .agg(agg_exprs)
        .rename({"Person_ctry_code": "iso3c", "filing": "year"})
        .sort(["iso3c", "year"])
    )

    country_agg.write_csv(
        os.path.join(OUTPUT_DIR, FINAL_COUNTRY_FILE)
    )

    merged.write_parquet(
        os.path.join(OUTPUT_DIR, FINAL_PATENT_FILE)
    )

if __name__ == "__main__":
    main()
```

# data construction
```{r eval= TRUE, echo= TRUE, warning= FALSE, message= FALSE}
# data construction script
# pivoting datasets, interpolating the Park index, and adding iso3c keys not included in this script
rm(list = ls())

library(data.table)
library(dplyr)

options(dplyr.summarise.inform = FALSE)

# load individual datasets
pqi      <- fread("data/OECD_country_year_final.csv")
fd       <- fread("data/FD_Final.csv")
vc       <- fread("data/VC_final.csv")
counts   <- fread("data/counts_res_final.csv")
controls <- fread("data/Controls_final.csv")
park     <- fread("data/Park_final.csv")

# ------------------------------------------------------------
# CLEAN MISSING VALUES
# ------------------------------------------------------------

clean_missing <- function(df) {
  df[df == ".."] <- NA
  df[df == "NA"] <- NA
  df[df == ""]   <- NA
  return(df)
}

pqi      <- clean_missing(pqi)
fd       <- clean_missing(fd)
vc       <- clean_missing(vc)
counts   <- clean_missing(counts)
controls <- clean_missing(controls)
park     <- clean_missing(park)

# ------------------------------------------------------------
# REMOVE DUPLICATE RESEARCHER COLUMN FROM COUNTS
# ------------------------------------------------------------

counts <- counts %>%
  select(-researchers_per_million)

# ------------------------------------------------------------
# MERGE DATASETS STEP BY STEP
# ------------------------------------------------------------

df <- pqi %>%
  left_join(park %>% select(iso3c, year, ipp_index_IP_transformed),
            by = c("iso3c", "year")) %>%
  left_join(fd,       by = c("iso3c", "year")) %>%
  left_join(vc,       by = c("iso3c", "year")) %>%
  left_join(counts,   by = c("iso3c", "year")) %>%
  left_join(controls, by = c("iso3c", "year"))

# ------------------------------------------------------------
# FORCE NUMERIC VARIABLES
# ------------------------------------------------------------

numeric_vars <- c(
  "researchers_per_million",
  "population_total",
  "gdp_pc_const2015usd",
  "bank_credit_gdp",
  "market_cap_gdp",
  "VC_investment",
  "trade_percent_gdp",
  "rd_expenditure_percent_gdp",
  "tertiary_enrollment_percent",
  "patent_applications_residents",
  "breakthrough_count",
  "patent_count",
  "ipp_index_IP_transformed"
)

for (v in numeric_vars) {
  if (v %in% names(df)) {
    df[[v]] <- as.numeric(df[[v]])
  }
}

# ------------------------------------------------------------
# DERIVED VARIABLES
# ------------------------------------------------------------

df <- df %>%
  mutate(
    # Researchers total
    researchers_total =
      researchers_per_million * (population_total / 1e6),
    
    # Patents per 1000 researchers
    patents_per_1000_researchers =
      (patent_applications_residents / researchers_total) * 1000,
    
    patents_per_1000_researchers =
      ifelse(
        is.infinite(patents_per_1000_researchers) |
        patents_per_1000_researchers < 0,
        NA,
        patents_per_1000_researchers
      ),
    
    # Scale quality index
    quality_index_100 = avg_quality_index_4 * 100,
    
    # VC scaling
    VC_investment_pct = VC_investment * 100,
    
    # Log transforms
    ln_patents   = log(patents_per_1000_researchers + 1),
    ln_gdp_pc    = log(gdp_pc_const2015usd + 1),
    ln_bank      = log(bank_credit_gdp + 1),
    ln_market    = log(market_cap_gdp + 1),
    ln_vc        = log(VC_investment_pct + 1),
    ln_trade     = log(trade_percent_gdp + 1),
    ln_rd        = log(rd_expenditure_percent_gdp + 1),
    ln_tertiary  = log(tertiary_enrollment_percent + 1),
    
    # Mean-center IPR
    ipr_c =
      ipp_index_IP_transformed -
      mean(ipp_index_IP_transformed, na.rm = TRUE),
    
    # Interaction terms
    ln_bank_x_ipr   = ln_bank   * ipr_c,
    ln_market_x_ipr = ln_market * ipr_c,
    ln_vc_x_ipr     = ln_vc     * ipr_c
  )

# ------------------------------------------------------------
# SAVE FINAL PANEL
# ------------------------------------------------------------

fwrite(df, "data/monarch_panel_transformed.csv")

summary(df)

```
# baseline twfe
```{r results='asis', echo=TRUE, eval= TRUE, warning= FALSE, message= FALSE}
# baseline twfe models

rm(list = ls())

library(data.table)
library(dplyr)
library(plm)
library(lmtest)
library(sandwich)
library(stargazer)

options(dplyr.summarise.inform = FALSE)

# load data

df <- fread("data/monarch_panel_transformed.csv")


if (!dir.exists("tables")) {
  dir.create("tables")
}

# clustered se

cluster_se <- function(model) {
  sqrt(diag(vcovHC(model, type = "HC1", cluster = "group")))
}

# function

run_twfe_incremental <- function(depvar, fd, fd_x_ipr, outfile, title) {

# maximize samples by finance type

  base <- df %>%
    filter(
      !is.na(.data[[depvar]]),
      !is.na(.data[[fd]]),
      !is.na(ipr_c)
    )

  panel <- pdata.frame(base, index = c("iso3c", "year"))
# specifications

  f1 <- as.formula(paste(depvar, "~", fd, "+ ipr_c +", fd_x_ipr))
  f2 <- update(f1, . ~ . + ln_gdp_pc)
  f3 <- update(f2, . ~ . + ln_trade)
  f4 <- update(f3, . ~ . + ln_rd)
  f5 <- update(f4, . ~ . + ln_tertiary)

  m1 <- plm(f1, data = panel, model = "within", effect = "twoways")
  m2 <- plm(f2, data = panel, model = "within", effect = "twoways")
  m3 <- plm(f3, data = panel, model = "within", effect = "twoways")
  m4 <- plm(f4, data = panel, model = "within", effect = "twoways")
  m5 <- plm(f5, data = panel, model = "within", effect = "twoways")
  
  html_table <- capture.output(
  stargazer(
    m1, m2, m3, m4, m5,
    type = "html",
    title = title,
    dep.var.caption = ifelse(
      depvar == "quality_index_100",
      "Dependent Variable: Patent Quality (0–100)",
      "Dependent Variable: ln(Patents per 1,000 Researchers)"
    ),
    se = list(
      cluster_se(m1),
      cluster_se(m2),
      cluster_se(m3),
      cluster_se(m4),
      cluster_se(m5)
    ),
    omit.stat = c("ser", "f"),
    notes = c(
      "Country and year fixed effects included in all models.",
      "Standard errors clustered by country.",
      "* p<0.1; ** p<0.05; *** p<0.01"
    ),
    no.space = TRUE
  )
)

cat(paste(html_table, collapse = "\n"))


# latex tables
  stargazer(
    m1, m2, m3, m4, m5,
    type = "latex",
    out  = outfile,
    title = title,
    dep.var.caption = ifelse(
      depvar == "quality_index_100",
      "Dependent Variable: Patent Quality (0–100)",
      "Dependent Variable: ln(Patents per 1,000 Researchers)"
    ),
    se = list(
      cluster_se(m1),
      cluster_se(m2),
      cluster_se(m3),
      cluster_se(m4),
      cluster_se(m5)
    ),
    omit.stat = c("ser", "f"),
    notes = c(
      "Country and year fixed effects included in all models.",
      "Standard errors clustered by country.",
      "* p<0.1; ** p<0.05; *** p<0.01"
    ),
    no.space = TRUE
  )

  return(list(m1, m2, m3, m4, m5))
}

# quality models

market_quality <- run_twfe_incremental(
  depvar   = "quality_index_100",
  fd       = "ln_market",
  fd_x_ipr = "ln_market_x_ipr",
  outfile  = "tables/twfe_market_quality.tex",
  title    = "Market Finance and Patent Quality"
)

bank_quality <- run_twfe_incremental(
  depvar   = "quality_index_100",
  fd       = "ln_bank",
  fd_x_ipr = "ln_bank_x_ipr",
  outfile  = "tables/twfe_bank_quality.tex",
  title    = "Bank Finance and Patent Quality"
)

vc_quality <- run_twfe_incremental(
  depvar   = "quality_index_100",
  fd       = "ln_vc",
  fd_x_ipr = "ln_vc_x_ipr",
  outfile  = "tables/twfe_vc_quality.tex",
  title    = "Venture Capital and Patent Quality"
)

# quantity models

market_quantity <- run_twfe_incremental(
  depvar   = "ln_patents",
  fd       = "ln_market",
  fd_x_ipr = "ln_market_x_ipr",
  outfile  = "tables/twfe_market_quantity.tex",
  title    = "Market Finance and Patent Quantity"
)

bank_quantity <- run_twfe_incremental(
  depvar   = "ln_patents",
  fd       = "ln_bank",
  fd_x_ipr = "ln_bank_x_ipr",
  outfile  = "tables/twfe_bank_quantity.tex",
  title    = "Bank Finance and Patent Quantity"
)

vc_quantity <- run_twfe_incremental(
  depvar   = "ln_patents",
  fd       = "ln_vc",
  fd_x_ipr = "ln_vc_x_ipr",
  outfile  = "tables/twfe_vc_quantity.tex",
  title    = "Venture Capital and Patent Quantity"
)

```

# zinb models
```{r results='asis', echo=TRUE, eval= TRUE, warning= FALSE, message= FALSE}
# ZINB MODELS

library(data.table)
library(pscl)
library(modelsummary)
library(dplyr)
library(knitr)

df <- fread("data/monarch_panel_transformed.csv")

# center fd variables
df[, ln_bank_c   := ln_bank   - mean(ln_bank,   na.rm = TRUE)]
df[, ln_market_c := ln_market - mean(ln_market, na.rm = TRUE)]
df[, ln_vc_c     := ln_vc     - mean(ln_vc,     na.rm = TRUE)]

df[, ln_bank_x_ipr_c   := ln_bank_c   * ipr_c]
df[, ln_market_x_ipr_c := ln_market_c * ipr_c]
df[, ln_vc_x_ipr_c     := ln_vc_c     * ipr_c]

df[, ln_internal_patents := log(patent_count)]

if (!dir.exists("tables")) {
  dir.create("tables")
}

# zinb with incremental controls
run_zinb_incremental <- function(finance_var, latex_name, title_name) {

  fd_c  <- paste0(finance_var, "_c")
  fd_x  <- paste0(finance_var, "_x_ipr_c")

  controls <- c("ln_gdp_pc", "ln_trade", "ln_rd", "ln_tertiary")

  models <- list()

  for (i in 1:4) {

    intensity_controls <- paste(controls[1:i], collapse = " + ")

    formula_str <- paste0(
      "breakthrough_count ~ ",
      fd_c, " + ipr_c + ", fd_x,
      " + ", intensity_controls,
      " + offset(ln_internal_patents) | ",
      "ln_gdp_pc"
    )

    model <- zeroinfl(
      as.formula(formula_str),
      data = df,
      dist = "negbin"
    )

    models[[i]] <- model
  }

# save latex tables
  modelsummary(
    models,
    output = latex_name,
    stars = TRUE,
    statistic = "({std.error})",
    coef_omit = "Intercept",
    gof_omit = "IC|Log|Adj|Pseudo",
    title = title_name,
    notes = c(
      "Zero-Inflated Negative Binomial model.",
      "Count equation models breakthrough intensity conditional on entry.",
      "Selection equation models structural non-entry.",
      "Selection equation includes ln_gdp_pc only.",
      "Offset = log(total patents).",
      "Standard errors in parentheses."
    )
  )

# save html

  cat("\n\n")
cat("##", title_name, "\n\n")

for (j in 1:4) {

  cat("### Model", j, "\n\n")

  model_sum <- summary(models[[j]])

#intensity model
  count_coefs <- model_sum$coefficients$count

  count_table <- data.frame(
    Variable = rownames(count_coefs),
    Coefficient = round(count_coefs[,1], 3),
    Std_Error = round(count_coefs[,2], 3)
  )

  cat("#### Intensity (Negative Binomial Count Equation)\n\n")
  print(knitr::kable(count_table))
  cat("\n\n")

# selection model
  zero_coefs <- model_sum$coefficients$zero

  zero_table <- data.frame(
    Variable = rownames(zero_coefs),
    Coefficient = round(zero_coefs[,1], 3),
    Std_Error = round(zero_coefs[,2], 3)
  )

  cat("#### Selection (Logit Structural Zero Equation)\n\n")
  print(knitr::kable(zero_table))
  cat("\n\n")

  cat("Observations:", models[[j]]$n, "\n\n")
}

  invisible(models)
}

# run mkt
zinb_market <- run_zinb_incremental(
  "ln_market",
  "tables/zinb_market.tex",
  "ZINB: Market Finance and Breakthrough Innovation"
)

# run bank
zinb_bank <- run_zinb_incremental(
  "ln_bank",
  "tables/zinb_bank.tex",
  "ZINB: Bank Finance and Breakthrough Innovation"
)

# run vc
zinb_vc <- run_zinb_incremental(
  "ln_vc",
  "tables/zinb_vc.tex",
  "ZINB: Venture Capital and Breakthrough Innovation"
)

```

# data diagnostics and graphs

## breakthrough
```{r eval= TRUE, echo= TRUE, message= FALSE, warning= FALSE}
library(ggplot2)
library(dplyr)

# breakthrough count diagnostics (justifies model choice)

df <- fread("data/monarch_panel_transformed.csv")

cat("Total observations:", nrow(df), "\n")
cat("Zero breakthrough observations:", sum(df$breakthrough_count == 0, na.rm = TRUE), "\n")
cat("Percent zeros:", round(mean(df$breakthrough_count == 0, na.rm = TRUE) * 100, 2), "%\n")

cat("Mean breakthrough count:", mean(df$breakthrough_count, na.rm = TRUE), "\n")
cat("Variance breakthrough count:", var(df$breakthrough_count, na.rm = TRUE), "\n")

ggplot(df, aes(x = breakthrough_count)) +
  geom_histogram(binwidth = 1, fill = "steelblue1", color = "white") +
  coord_cartesian(xlim = c(0, 30)) +
  labs(
    title = "Distribution of Breakthrough Counts",
    x = "Breakthrough Count (Top 1% Patents)",
    y = "Frequency"
  ) +
  theme_minimal()
```
## patent quality distribution
```{r eval= TRUE, echo= TRUE, message= FALSE, warning= FALSE}
ggplot(df, aes(x = quality_index_100)) +
  geom_density(fill = "deeppink1", alpha = 0.4) +
  labs(
    title = "Distribution of Patent Quality Index",
    x = "Patent Quality (0-100)",
    y = "Density"
  ) +
  theme_minimal()
```
## distibution of FD variables
```{r fig.width= 15, fig.height= 5, echo= TRUE, eval= TRUE, warning= FALSE, message= FALSE}
library(dplyr)
library(tidyverse)
vars <- c("ln_market", "ln_bank", "ln_vc")

df_long <- df %>%
  select(all_of(vars)) %>%
  pivot_longer(everything())

ggplot(df_long, aes(x = value)) +
  geom_density(fill = "deeppink1", alpha = 0.4) +
  facet_wrap(~name, scales = "free") +
  theme_minimal() +
  labs(title = "Distribution of Financial Development Measures")

```
## corr plot
```{r warning= FALSE, message= FALSE, echo= TRUE, eval= TRUE}
library(corrplot)

corr_vars <- df %>%
  select(quality_index_100, ln_patents,
         ln_market, ln_bank, ln_vc,
         ipr_c, ln_gdp_pc, ln_trade,
         ln_rd, ln_tertiary) %>%
  na.omit()

corr_matrix <- cor(corr_vars)

corrplot(corr_matrix, method = "color", type = "upper",
         tl.cex = 0.8, number.cex = 0.7)
```
## interaction plots (marginal effects)
```{r echo= TRUE, eval= TRUE, message= FALSE, warning= FALSE}
library(plm)

twfe_quality <- plm(
  quality_index_100 ~ ln_market * ipr_c +
    ln_bank + ln_vc,
  data = df,
  index = c("iso3c", "year"),
  model = "within",
  effect = "twoways"
)

twfe_quantity <- plm(
  ln_patents ~ ln_market * ipr_c +
    ln_bank + ln_vc,
  data = df,
  index = c("iso3c", "year"),
  model = "within",
  effect = "twoways"
)
library(marginaleffects)

ipr_sd <- sd(df$ipr_c, na.rm = TRUE)

ln_market_seq <- seq(
  min(df$ln_market, na.rm = TRUE),
  max(df$ln_market, na.rm = TRUE),
  length.out = 100
)

ipr_values <- c(-ipr_sd, 0, ipr_sd)

# Quality
plot_predictions(
  twfe_quality,
  condition = list(
    ln_market = ln_market_seq,
    ipr_c = ipr_values
  )
) +
  labs(
    title = "Market Finance × IPR Interaction (TWFE)",
    x = "Market Finance (log)",
    y = "Predicted Patent Quality"
  ) +
  theme_minimal()

# Quantity
plot_predictions(
  twfe_quantity,
  condition = list(
    ln_market = ln_market_seq,
    ipr_c = ipr_values
  )
) +
  labs(
    title = "Market Finance × IPR Interaction (TWFE)",
    x = "Market Finance (log)",
    y = "Predicted Log Patents"
  ) +
  theme_minimal()
```

# robustness checks
- quadratic models
- lags
- idk some other stuff

## joint tests and nonlinearity tests
```{r echo= TRUE, eval= TRUE, message= FALSE, warning= FALSE}
# robustness and model analysis

library(dplyr)
library(plm)
library(lmtest)
library(sandwich)
library(car)

# center fd variables
df <- fread("data/monarch_panel_transformed.csv")

df_ext <- df %>%
  mutate(
    ln_bank_c   = ln_bank   - mean(ln_bank,   na.rm = TRUE),
    ln_market_c = ln_market - mean(ln_market, na.rm = TRUE),
    ln_vc_c     = ln_vc     - mean(ln_vc,     na.rm = TRUE),
    
    ln_bank_x_ipr   = ln_bank_c * ipr_c,
    ln_market_x_ipr = ln_market_c * ipr_c,
    ln_vc_x_ipr     = ln_vc_c * ipr_c,

    ln_bank_c2   = ln_bank_c^2,
    ln_market_c2 = ln_market_c^2,
    ln_vc_c2     = ln_vc_c^2
  )

panel_ext <- pdata.frame(df_ext, index = c("iso3c", "year"))

# clustered se
vcov_clust <- function(x) vcovHC(x, method = "arellano", cluster = "group")

# run models, see where squared terms are justified

cat("\n testing for nonlinearity \n")

#  formulas to check squared term p-values

check_quad <- function(dv, base_var) {
  f <- as.formula(paste0(dv, " ~ ", base_var, "_c + ", base_var, "_c2 + ipr_c + ", 
                        base_var, "_x_ipr + ln_gdp_pc + ln_trade + ln_rd"))
  
  m <- plm(f, data = panel_ext, model = "within", effect = "twoways")
  
  cat("\nChecking Quadratic for:", dv, "vs", base_var, "\n")
  # square term included
  print(coeftest(m, vcov = vcov_clust(m))[2, ]) 
}

check_quad("quality_index_100", "ln_market")
check_quad("quality_index_100", "ln_bank")    # EXPECTED: significant
check_quad("quality_index_100", "ln_vc")
check_quad("ln_patents",        "ln_market")
check_quad("ln_patents",        "ln_bank")
check_quad("ln_patents",        "ln_vc")        # EXPECTED: significant

# final models and joint tests
cat("\n joint significance tests \n")

run_final <- function(dv, base_var, use_quad = FALSE) {
  
  main_vars <- if(use_quad) {
    paste0(base_var, "_c + ", base_var, "_c2")
  } else {
    paste0(base_var, "_c")
  }
  
  f <- as.formula(paste0(dv, " ~ ", main_vars, " + ipr_c + ", base_var, "_x_ipr + ln_gdp_pc + ln_trade + ln_rd"))
  m <- plm(f, data = panel_ext, model = "within", effect = "twoways")
  
  cat("\n", paste(rep("-", 40), collapse = ""), "\n")
  cat("FINAL MODEL:", dv, "by", base_var, "(Quadratic =", use_quad, ")\n")
  
  # joint signif
  hyp <- if(use_quad) {
    c(paste0(base_var, "_c = 0"), paste0(base_var, "_c2 = 0"), paste0(base_var, "_x_ipr = 0"))
  } else {
    c(paste0(base_var, "_c = 0"), paste0(base_var, "_x_ipr = 0"))
  }
  
  cat("\n[Joint Significance Test]\n")
  print(linearHypothesis(m, hyp, vcov = vcov_clust))
  
  # within fit
  cat("\n[Within R-squared]:", summary(m)$r.squared[1], "\n")
}

# quality final
run_final("quality_index_100", "ln_market", use_quad = FALSE)
run_final("quality_index_100", "ln_bank",   use_quad = TRUE)
run_final("quality_index_100", "ln_vc",     use_quad = FALSE)

# quantity final
run_final("ln_patents",        "ln_market", use_quad = FALSE)
run_final("ln_patents",        "ln_bank",   use_quad = FALSE)
run_final("ln_patents",        "ln_vc",     use_quad = TRUE)
```

# Variable Glossary

**Identifiers**

- `iso3c` - Three-letter ISO country code. Primary country identifier used to merge OECD PQI, financial development, institutional, and macroeconomic datasets.
- `year` - Observation year (country-year panel structure).
- `Country Name` - Human-readable country name (not used in estimation; included for clarity).

**Patent Quality Indicators (OECD PQI)**

All quality indicators are aggregated to the country-year level using the mean across patents.

- `avg_patent_scope_norm` - Average normalized patent scope; number of jurisdictions in which a patent family is filed (proxy for economic value and international relevance).
- `avg_family_size_norm` - Average normalized patent family size; number of related patent filings across offices (proxy for strategic and economic importance).
- `avg_grant_lag_norm` - Average normalized grant lag; time between application and grant (proxy for complexity).
- `avg_bwd_cits_norm` - Average normalized backward citations; references to prior patents (knowledge base intensity).
- `avg_npl_cits_norm` - Average normalized non-patent literature citations; references to scientific publications (science linkage).
- `avg_claims_norm` - Average normalized number of claims; legal scope of protection.
- `avg_fwd_cits5_norm` - Average normalized forward citations within 5 years; short-run technological impact.
- `avg_fwd_cits7_norm` - Average normalized forward citations within 7 years; medium-run technological impact.
- `avg_generality` - Technological breadth index (0-1); dispersion of forward citations across technology classes.
- `avg_originality` - Citation diversity index (0-1); dispersion of backward citations across technology classes.
- `avg_radicalness` - Novelty index (0-1); degree to which cited prior art differs from focal patent classification.
- `avg_quality_index_4` - Composite patent quality index based on four core indicators.
- `avg_quality_index_6` - Composite patent quality index based on six indicators.
- `quality_index_100` - `avg_quality_index_4` * 100 for interpretability (used in TWFE models).
- `avg_renewal` - Average years a patent is renewed; proxy for economic value (where available).

**Breakthrough Innovation Variables**

- `breakthrough` - (patent-level, in Python step) Binary indicator equal to 1 if the patent belongs to the top 1% most cited patents within cohort, 0 otherwise.
- `breakthrough_count` - Country-year count of breakthrough patents (sum of top 1% patents).
- `patent_count` - Total number of patents in OECD PQI data for that country–year.
- `pct_breakthrough` - Share of patents in a country-year that qualify as breakthroughs: `breakthrough_count` / `patent_count`.
- `ln_internal_patents` - Log of `patent_count`; used as an offset in count models.

**Patent Quantity Measures**

- `patent_applications_residents` - Resident patent applications (WDI source).
- `researchers_per_million` - Researchers per million inhabitants; used to normalize patent output.
- `population_total` - Total population; used to compute total researchers.
- `researchers_total` - Computed as: `researchers_per_million` * (`population_total` / 1,000,000).
- `patents_per_1000_researchers` - Scaled patent intensity measure: `patent_applications_residents` / `researchers_total` * 1000.
- `ln_patents` - Log transformation of patents per 1,000 researchers (+1 shift).

**Financial Development Variables**

- `bank_credit_gdp` - Domestic credit to private sector (% of GDP). Proxy for banking sector depth.
- `market_cap_gdp` - Market capitalization of listed domestic companies (% of GDP). Proxy for stock market depth.
- `VC_investment` - Venture capital investment as % of GDP.
- `VC_investment_pct` - `VC_investment` * 100, rescaled to match percentage units of other financial variables.
- `ln_bank` - Log of `bank_credit_gdp` + 1.
- `ln_market` - Log of `market_cap_gdp` + 1.
- `ln_vc` - Log of `VC_investment_pct` + 1.
- `[fd_var]_x_ipr` - Interaction term between financial development variable and institutional quality.
- `[fd_var]_c` - Mean-centered financial variable (used only in ZINB models).
- `[fd_var]_x_ipr_c` - Interaction between centered finance variable and centered IPR (ZINB only).

**Institutional Variable**

- `ipp_index_IP_transformed` - Park Intellectual Property Protection Index (0-5 scale); five-year fill interpolation.
- `ipr_c` - Mean-centered Park index. Used to improve interpretation of interaction coefficients.

**Macroeconomic Controls**

All controls are log-transformed (+1 shift where necessary).

- `gdp_pc_const2015usd` - GDP per capita (constant 2015 USD).
- `ln_gdp_pc` - Log GDP per capita.
- `trade_percent_gdp` - Trade openness (% of GDP).
- `ln_trade` - Log trade openness.
- `rd_expenditure_percent_gdp` - R&D expenditure (% of GDP).
- `ln_rd` - Log R&D expenditure.
- `tertiary_enrollment_percent` - Gross tertiary enrollment (%).
- `ln_tertiary` - Log tertiary enrollment.

**Model-Specific Parameters**

- `Log(theta)` - Log of dispersion parameter in negative binomial models. Captures overdispersion relative to Poisson.


